{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "review_datas = [json.loads(line) for line in open('/Users/xuxinhe/Desktop/finalproject/yelp-data/yelp_academic_dataset_review.json', 'r', encoding='utf-8')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get specific date data from review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review_id': 'KU_O5udG6zpxOg-VcAEodg', 'user_id': 'mh_-eMZ6K5RLWhZyISBhwA', 'business_id': 'XQfwVwDr-v0ZS3_CbbE5Xw', 'stars': 3.0, 'useful': 0, 'funny': 0, 'cool': 0, 'text': \"If you decide to eat here, just be aware it is going to take about 2 hours from beginning to end. We have tried it multiple times, because I want to like it! I have been to it's other locations in NJ and never had a bad experience. \\n\\nThe food is good, but it takes a very long time to come out. The waitstaff is very young, but usually pleasant. We have just had too many experiences where we spent way too long waiting. We usually opt for another diner or restaurant on the weekends, in order to be done quicker.\", 'date': '2018-07-07 22:09:11'}\n"
     ]
    }
   ],
   "source": [
    "print(review_datas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_specific_date_data(start, end, review_datas, outPath):\n",
    "  res = []\n",
    "  res = find_specific_date_data(review_datas, start, end, res)\n",
    "  with open(outPath, 'w') as  f:\n",
    "        json.dump(res, f)\n",
    "  \n",
    "def find_specific_date_data(reviewdatas, start, end, res):\n",
    "  for j in reviewdatas:\n",
    "    dateti = j['date'].split(' ')\n",
    "    specific_date = pd.to_datetime(dateti[0])\n",
    "    if specific_date > start and specific_date < end:\n",
    "      tempdict = {}\n",
    "      tempdict['user_id'] = j['user_id']\n",
    "      tempdict['review_id'] = j['review_id']\n",
    "      tempdict['business_id'] = j['business_id']\n",
    "      tempdict['review'] = j['text']\n",
    "      time_data = j['date'].split(' ')\n",
    "      tempdict['date'] = time_data[0]\n",
    "      tempdict['time'] = time_data[1]\n",
    "      tempdict['actual_yelp_score'] = j['stars']\n",
    "      res.append(tempdict)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from '2018-08-01' to '2018-08-31' general time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general date\n",
    "\n",
    "start =  pd.to_datetime('2018-08-01')\n",
    "end = pd.to_datetime('2018-08-31')\n",
    "find_all_specific_date_data(start, end, review_datas, 'timesplitData/nocovid_19date/nocovid_19date.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from '2020-08-01' to '2020-08-31' covid_19 time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general date\n",
    "\n",
    "start =  pd.to_datetime('2020-08-01')\n",
    "end = pd.to_datetime('2020-08-31')\n",
    "find_all_specific_date_data(start, end, review_datas, 'timesplitData/covid_19date/covid_19date.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from 2018 thanks giving date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 thanks giving date \n",
    "start =  pd.to_datetime('2018-11-01')\n",
    "end = pd.to_datetime('2018-11-30')\n",
    "find_all_specific_date_data(start, end, review_datas, 'timesplitData/thanksgiving/thanksgiving18/thanksgiving18.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from 2019 thanks giving date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019 thanks giving date\n",
    "start =  pd.to_datetime('2019-11-18')\n",
    "end = pd.to_datetime('2019-12-13')\n",
    "find_all_specific_date_data(start, end, review_datas, 'timesplitData/thanksgiving/thanksgiving19/thanksgiving19.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from 2020 thanks giving date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020 thanks giving date\n",
    "start =  pd.to_datetime('2020-11-16')\n",
    "end = pd.to_datetime('2020-12-11')\n",
    "find_all_specific_date_data(start, end, review_datas, 'timesplitData/thanksgiving/thanksgiving20/thanksgiving20.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from 2021 thanks giving date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021 thanks giving date\n",
    "start =  pd.to_datetime('2021-11-15')\n",
    "end = pd.to_datetime('2021-12-10')\n",
    "find_all_specific_date_data(start, end, review_datas, 'timesplitData/thanksgiving/thanksgiving21/thanksgiving21.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random select 60 data from the select month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "def random_choose_data(num, input_path, output_path):\n",
    "  with open(input_path, encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    all_data = json.loads(line)\n",
    "    res = sample(all_data, num)\n",
    "    f.close()\n",
    "  with open(output_path, 'w') as  f:\n",
    "    json.dump(res, f)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_choose_data(50, 'timesplitData/nocovid_19date/nocovid_19date.json', 'choose_data/nocovid_19date.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_choose_data(50, 'timesplitData/covid_19date/covid_19date.json', 'choose_data/covid_19date.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_choose_data(50, 'timesplitData/thanksgiving/thanksgiving18/thanksgiving18.json', 'choose_data/thanksgiving/thanksgiving18.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_choose_data(50, 'timesplitData/thanksgiving/thanksgiving19/thanksgiving19.json', 'choose_data/thanksgiving/thanksgiving19.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_choose_data(50, 'timesplitData/thanksgiving/thanksgiving20/thanksgiving20.json', 'choose_data/thanksgiving/thanksgiving20.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_choose_data(50, 'timesplitData/thanksgiving/thanksgiving21/thanksgiving21.json', 'choose_data/thanksgiving/thanksgiving21.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the business file information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_business_information(business_path, input_path, out_path):\n",
    "  res = []\n",
    "  business_data = pd.read_json(business_path, lines=True)\n",
    "  with open(input_path, encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    choose_data = json.loads(line)\n",
    "    f.close()\n",
    "  for r in choose_data:\n",
    "    i = {}\n",
    "    busin_info = business_data[business_data['business_id'] == r['business_id']] \n",
    "    dict1 = busin_info.to_dict()\n",
    "    i['review_id'] = r['review_id']\n",
    "    i['user_id'] = r['user_id']\n",
    "    i['business_id'] = r['business_id']\n",
    "    i['review'] = [r['review']]\n",
    "    i['date'] = r['date']\n",
    "    i['time'] = r['time']\n",
    "    i['actual_yelp_score'] = r['actual_yelp_score']\n",
    "    \n",
    "    temp_cat = list(dict1['categories'].values())\n",
    "    i['categories'] = temp_cat[0]\n",
    "    \n",
    "    temp_city = list(dict1['city'].values())\n",
    "    i['city'] = temp_city[0]\n",
    "    \n",
    "    temp_state = list(dict1['state'].values())\n",
    "    i['state'] = temp_state[0]\n",
    "    \n",
    "    temp_stars = list(dict1['stars'].values())\n",
    "    i['stars'] = temp_stars[0]\n",
    "    \n",
    "    temp_review_count = list(dict1['review_count'].values())\n",
    "    i['review_count'] = temp_review_count[0]\n",
    "    \n",
    "    res.append(i)\n",
    "  with open(out_path, 'w') as  f:\n",
    "    json.dump(res, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_business_information('/Users/xuxinhe/Desktop/finalproject/yelp-data/yelp_academic_dataset_business.json', 'choose_data/covid_19date.json', 'final_data/covid_19date.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_business_information('/Users/xuxinhe/Desktop/finalproject/yelp-data/yelp_academic_dataset_business.json', 'choose_data/nocovid_19date.json', 'final_data/nocovid_19date.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_business_information('/Users/xuxinhe/Desktop/finalproject/yelp-data/yelp_academic_dataset_business.json', 'choose_data/thanksgiving/thanksgiving18.json', 'final_data/thanksgiving18.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_business_information('/Users/xuxinhe/Desktop/finalproject/yelp-data/yelp_academic_dataset_business.json', 'choose_data/thanksgiving/thanksgiving19.json', 'final_data/thanksgiving19.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_business_information('/Users/xuxinhe/Desktop/finalproject/yelp-data/yelp_academic_dataset_business.json', 'choose_data/thanksgiving/thanksgiving20.json', 'final_data/thanksgiving20.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_business_information('/Users/xuxinhe/Desktop/finalproject/yelp-data/yelp_academic_dataset_business.json', 'choose_data/thanksgiving/thanksgiving21.json', 'final_data/thanksgiving21.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
